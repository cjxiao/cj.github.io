<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="CJ&#39;s SpaceX">
<meta property="og:url" content="http://hiack.com/index.html">
<meta property="og:site_name" content="CJ&#39;s SpaceX">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CJ&#39;s SpaceX">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://hiack.com/"/>





  <title>CJ's SpaceX</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">CJ's SpaceX</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/02/22/accessing-database-or-kafka-from-spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/22/accessing-database-or-kafka-from-spark/" itemprop="url">Accessing Database/Kafka from Spark</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-22T15:23:24+08:00">
                2018-02-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h1><p>As suggested in <a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html#design-patterns-for-using-foreachrdd" target="_blank" rel="noopener">Design Patterns for using foreachRDD</a>, when you access external systems from withn RDD handler, cautions must be taken to avoid the common mistakes, ie. you should create connections to external systems inside the RDD handler.</p>
<p>And, in order to minimize the cost in connection creation and improve the IO throughput, the common technique for DB connections is using <strong>Connection Pool</strong>.</p>
<p>However, when it comes to <strong>Kafka Consumer/Producer</strong>, things become different:</p>
<ol>
<li>Kafka Producer/Consumer creation is much more time-consuming, as it needs to discover all partition leader.</li>
<li>Kafka producer is thread-safe.</li>
</ol>
<p>So, a better approach for Kafka accessing in Spark is taking advantage of Spark <a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#broadcast-variables" target="_blank" rel="noopener">Broadcast Variables</a> and Scala <code>lazy val</code>.</p>
<p>For details, refert to <a href="https://allegro.tech/2015/08/spark-kafka-integration.html" target="_blank" rel="noopener">Spark and Kafka integration patterns</a>.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/02/16/2018/02/kafka-design-implementation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/16/2018/02/kafka-design-implementation/" itemprop="url">Kafka Design & Implementation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-16T17:55:27+08:00">
                2018-02-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="4-Design"><a href="#4-Design" class="headerlink" title="4. Design"></a>4. Design</h1><h2 id="4-1-Motivation"><a href="#4-1-Motivation" class="headerlink" title="4.1 Motivation"></a>4.1 Motivation</h2><p>To Support:</p>
<ul>
<li>High throughput</li>
<li>Large data backlogs</li>
<li>Low latency</li>
<li>Partitioned, distributed, real-time processing</li>
<li>Fault tolerance</li>
</ul>
<h2 id="4-2-Persistence"><a href="#4-2-Persistence" class="headerlink" title="4.2 Persistence"></a>4.2 Persistence</h2><h3 id="Dont’-fear-the-filesystem"><a href="#Dont’-fear-the-filesystem" class="headerlink" title="Dont’ fear the filesystem"></a>Dont’ fear the filesystem</h3><ul>
<li>Kafka relies heavily on the filesystem for storing and <strong>caching</strong> messages.</li>
<li><p>Disks are both much slower and much faster than people expect depending on how they are used.</p>
</li>
<li><p>Using the filesystem and relying on pagecache is superior to maintaining an in-memory cache or other structure:</p>
<ul>
<li>automatic access to all free memory</li>
<li>compact byte structure</li>
<li>without GC penalties</li>
<li>this cache will stay warm even if the service is restarted</li>
</ul>
</li>
<li><p>All data is immediately written to a persistent log on the filesystem without necessarily flushing to disk.</p>
</li>
</ul>
<h3 id="Constant-Time-Suffices"><a href="#Constant-Time-Suffices" class="headerlink" title="Constant Time Suffices"></a>Constant Time Suffices</h3><ul>
<li>Btree operations are O(log N), still slow for disk operations</li>
<li>Simple reads and appends to files as is commonly the case with logging solutions:<ul>
<li>O(1)</li>
<li>reads do not block writes or each other</li>
</ul>
</li>
</ul>
<h2 id="4-3-Efficiency"><a href="#4-3-Efficiency" class="headerlink" title="4.3 Efficiency"></a>4.3 Efficiency</h2><p>(combination of pagecache and sendfile)  </p>
<ul>
<li>Disk IO</li>
<li>Too many small I/O operations<ul>
<li>Message set abstraction (Batching)</li>
</ul>
</li>
<li>Excessive byte copying<ul>
<li>Standardized binary message format that is shared by the producer, the broker, and the consumer</li>
<li>Message log on the disk in the same format used by the producer and consumer</li>
<li>Enable efficient network transfer of persistent log chunks (<code>sendfile</code>, zero-copy): send the data from pagecache to the network directly</li>
</ul>
</li>
</ul>
<h3 id="End-to-end-Batch-Compression"><a href="#End-to-end-Batch-Compression" class="headerlink" title="End-to-end Batch Compression"></a>End-to-end Batch Compression</h3><p>(compression on batch of messages)</p>
<ul>
<li>This batch of messages will be written in compressed form and will remain compressed in the log and will only be decompressed by the consumer.</li>
</ul>
<h2 id="4-4-The-Producer"><a href="#4-4-The-Producer" class="headerlink" title="4.4 The Producer"></a>4.4 The Producer</h2><h3 id="Load-Balancing"><a href="#Load-Balancing" class="headerlink" title="Load Balancing"></a>Load Balancing</h3><ul>
<li>The producer sends data directly to the broker that is the leader for the partition without any intervening routing tier. </li>
<li>To help the producer do this all Kafka nodes can answer a request for metadata about which servers are alive and where the leaders for the partitions of a topic are at any given time.</li>
<li>The client controls which partition it publishes messages to.</li>
</ul>
<h3 id="Asynchronous-send"><a href="#Asynchronous-send" class="headerlink" title="Asynchronous send"></a>Asynchronous send</h3><ul>
<li>Batching and asynchronous sending of messages</li>
<li>Configurable to trade off a small amount of additional latency for better throughput</li>
</ul>
<h2 id="4-5-The-Consumer"><a href="#4-5-The-Consumer" class="headerlink" title="4.5 The Consumer"></a>4.5 The Consumer</h2><ul>
<li><em>Fetch</em> from partition leaders</li>
<li>Specify the <code>offset</code> in the log, and receives back a chunk of log beginning from that position</li>
</ul>
<h3 id="Push-vs-Pull"><a href="#Push-vs-Pull" class="headerlink" title="Push vs. Pull"></a>Push vs. Pull</h3><p><strong>Data is pushed to the broker from the producer and pulled from the broker by the consumer.</strong></p>
<ul>
<li>Support diverse comsuming rate</li>
<li>Lend itself to aggressive batching of data sent to the consumer<ul>
<li>Get optimal batching without introducing unnecessary latency</li>
</ul>
</li>
</ul>
<p>The deficiency of a naive pull-based system: busy-waiting for data to arrive.</p>
<ul>
<li>To avoid this we have parameters in our pull request that allow the consumer request to block in a “long poll” waiting until data arrives</li>
</ul>
<h3 id="Consumer-Position"><a href="#Consumer-Position" class="headerlink" title="Consumer Position"></a>Consumer Position</h3><p>The position of a consumer in each partition is just a single integer, the offset of the next message to consume.</p>
<h3 id="Offline-Data-Load"><a href="#Offline-Data-Load" class="headerlink" title="Offline Data Load"></a>Offline Data Load</h3><h2 id="4-6-Message-Delivery-Semantics"><a href="#4-6-Message-Delivery-Semantics" class="headerlink" title="4.6 Message Delivery Semantics"></a>4.6 Message Delivery Semantics</h2><ul>
<li>If a producer attempts to publish a message and experiences a network error it cannot be sure if this error happened before or after the message was committed.</li>
<li>Since 0.11.0.0, the Kafka producer also supports an idempotent delivery option (<em>enable.idempotence</em>) which guarantees that resending will not result in duplicate entries in the log.<ul>
<li>To achieve this, the broker assigns each producer an ID and deduplicates messages using a sequence number that is sent by the producer along with every message.</li>
</ul>
</li>
<li>Also beginning with 0.11.0.0, the producer supports the ability to send messages to multiple topic partitions using transaction-like semantics: i.e. either all messages are successfully written or none of them are. <ul>
<li>Exactly-once processing between Kafka topics</li>
</ul>
</li>
<li>Allow the producer to specify the durability level: Committed, Completely Asynchronous, or only the Leader has it.</li>
<li>When consuming from a Kafka topic and producing to another topic (as in a Kafka Streams application), we can leverage the new <strong>transactional producer</strong> capabilities in 0.11.0.0.<ul>
<li>The consumer’s position is stored as a message in a topic.</li>
<li>Visiblility to other consumers depends on their <strong>isolation level</strong>, like read_uncommitted, read_committed.</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">So effectively Kafka supports exactly-once delivery in Kafka Streams, and the transactional producer/consumer can be used generally to provide exactly-once delivery when transfering and processing data between Kafka topics. Exactly-once delivery for other destination systems generally requires cooperation with such systems, but Kafka provides the offset which makes implementing this feasible (see also Kafka Connect). Otherwise, Kafka guarantees at-least-once delivery by default, and allows the user to implement at-most-once delivery by disabling retries on the producer and committing offsets in the consumer prior to processing a batch of messages.</span><br></pre></td></tr></table></figure>
<h2 id="4-7-Replication"><a href="#4-7-Replication" class="headerlink" title="4.7 Replication"></a>4.7 Replication</h2><ul>
<li>All reads and writes go to the leader of the partition.</li>
<li>Having the followers pull from the leader has the nice property of allowing the follower to naturally batch together log entries they are applying to their log.</li>
</ul>
<p>For Kafka node liveness (<em>in-sync</em>) has two conditions</p>
<ol>
<li>A node must be able to maintain its session with ZooKeeper (via ZooKeeper’s heartbeat mechanism)</li>
<li>If it is a slave it must replicate the writes happening on the leader and not fall “too far” behind</li>
</ol>
<ul>
<li>A message is considered <strong>committed</strong> when all in sync replicas (ISR) for that partition have applied it to their log</li>
<li>Only committed messages are ever given out to the consumer.<ul>
<li>The message can be committed, and consumed, even if the number of in-sync replicas is lower than the minimum (e.g. it can be as low as just the leader).</li>
</ul>
</li>
<li>Kafka will remain available in the presence of node failures after a short fail-over period, but may not remain available in the presence of network partitions. </li>
</ul>
<h3 id="Replicated-Logs-Quorums-ISRs-and-State-Machines-Oh-my"><a href="#Replicated-Logs-Quorums-ISRs-and-State-Machines-Oh-my" class="headerlink" title="Replicated Logs: Quorums, ISRs, and State Machines (Oh my!)"></a>Replicated Logs: Quorums, ISRs, and State Machines (Oh my!)</h3><ul>
<li>At its heart a Kafka partition is a replicated log.</li>
<li>Choose an up-to-date follower as the new leader</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka takes a slightly different approach to choosing its quorum set. Instead of majority vote, Kafka dynamically maintains a set of in-sync replicas (ISR) that are caught-up to the leader. Only members of this set are eligible for election as leader. A write to a Kafka partition is not considered committed until all in-sync replicas (conf: min.insync.replicas) have received the write. This ISR set is persisted to ZooKeeper whenever it changes. Because of this, any replica in the ISR is eligible to be elected leader. This is an important factor for Kafka&apos;s usage model where there are many partitions and ensuring leadership balance is important. With this ISR model and f+1 replicas, a Kafka topic can tolerate f failures without losing committed messages.</span><br></pre></td></tr></table></figure>
</li>
<li><p>Kafka does not require that crashed nodes recover with all their data intact.</p>
</li>
</ul>
<h3 id="Unclean-leader-election-What-if-they-all-die"><a href="#Unclean-leader-election-What-if-they-all-die" class="headerlink" title="Unclean leader election: What if they all die?"></a>Unclean leader election: What if they all die?</h3><ul>
<li>By default, Kafka chooses the second strategy and favor choosing a potentially inconsistent replica when all replicas in the ISR are dead (conf: unclean.leader.election.enable).</li>
</ul>
<h3 id="Availability-and-Durability-Guarantees"><a href="#Availability-and-Durability-Guarantees" class="headerlink" title="Availability and Durability Guarantees"></a>Availability and Durability Guarantees</h3><ul>
<li>Producers can choose whether they wait for the message to be acknowledged by 0,1 or all (-1) replicas.<ul>
<li><em>all</em>: all ISRs</li>
</ul>
</li>
</ul>
<h3 id="Replica-Management"><a href="#Replica-Management" class="headerlink" title="Replica Management"></a>Replica Management</h3><ul>
<li>Balance partitions within a cluster in a round-robin fashion to avoid clustering all partitions for high-volume topics on a small number of nodes</li>
<li>Balance leadership so that each node is the leader for a proportional share of its partitions</li>
<li>Leadership election:<ul>
<li>A <strong>naive</strong> implementation of leader election would end up running an election per partition for all partitions a node hosted when that node failed.</li>
<li>Instead, we elect one of the brokers as the <strong>“controller”</strong>. This controller detects failures at the broker level and is responsible for changing the leader of all affected partitions in a failed broker.</li>
</ul>
</li>
</ul>
<h2 id="4-8-Log-Compaction"><a href="#4-8-Log-Compaction" class="headerlink" title="4.8 Log Compaction"></a>4.8 Log Compaction</h2><p>Log compaction ensures that Kafka will always retain at least the last known value for each message key within the log of data for a single topic partition.</p>
<ul>
<li>For class of data streams are the log of changes to keyed, mutable data (for example, the changes to a database table)</li>
<li>Log compaction is a mechanism to give finer-grained <strong>per-record</strong> retention, rather than the coarser-grained time-based retention.</li>
</ul>
<h3 id="Log-Compaction-Basics"><a href="#Log-Compaction-Basics" class="headerlink" title="Log Compaction Basics"></a>Log Compaction Basics</h3><p><img src="/content/images/2018/02/kafka-design-implementation_log_compaction_basics_1.png" alt="logical structure of a Kafka log"></p>
<ul>
<li>All offsets remain valid positions in the log, even if the message with that offset has been compacted away.<ul>
<li>In this case this position is indistinguishable from the next highest offset that does appear in the log.</li>
<li>For example, in the picture above the offsets 36, 37, and 38 are all equivalent positions and a read beginning at any of these offsets would return a message set beginning with 38.</li>
</ul>
</li>
<li>A message with a key and a null payload will be treated as a delete from the log (delete marker).<ul>
<li>Will be cleaned out of the log after a period of time to free up space (delete retention point)</li>
</ul>
</li>
<li>The compaction is done in the background by periodically recopying log segments.<ul>
<li>Cleaning does not block reads and can be throttled.</li>
</ul>
</li>
</ul>
<h3 id="What-guarantees-does-log-compaction-provide"><a href="#What-guarantees-does-log-compaction-provide" class="headerlink" title="What guarantees does log compaction provide?"></a>What guarantees does log compaction provide?</h3><h3 id="Log-Compaction-Details"><a href="#Log-Compaction-Details" class="headerlink" title="Log Compaction Details"></a>Log Compaction Details</h3><p>Log compaction is handled by the log cleaner, a pool of background threads that recopy log segment files, removing records whose key appears in the head of the log.</p>
<ol>
<li>It chooses the log that has the <strong>highest ratio of log head to log tail</strong>.</li>
<li>It creates a succinct summary of the last offset for each key in the head of the log.</li>
<li>It recopies the log <strong>from beginning to end</strong> removing keys which have a later occurrence in the log. New, clean segments are swapped into the log immediately so the additional disk space required is just one additional log segment (not a fully copy of the log).</li>
<li>The summary of the log head is essentially just a space-compact hash table.</li>
</ol>
<h3 id="Configuring-The-Log-Cleaner"><a href="#Configuring-The-Log-Cleaner" class="headerlink" title="Configuring The Log Cleaner"></a>Configuring The Log Cleaner</h3><p>The <strong>active segment</strong> will not be compacted.</p>
<h2 id="4-9-Quotas"><a href="#4-9-Quotas" class="headerlink" title="4.9 Quotas"></a>4.9 Quotas</h2><p>control the broker resources used by each group of clients:</p>
<ul>
<li>Network bandwidth quotas</li>
<li>Request rate quotas</li>
</ul>
<h1 id="5-IMPLEMENTATION"><a href="#5-IMPLEMENTATION" class="headerlink" title="5. IMPLEMENTATION"></a>5. IMPLEMENTATION</h1><h2 id="5-1-Network-Layer"><a href="#5-1-Network-Layer" class="headerlink" title="5.1 Network Layer"></a>5.1 Network Layer</h2><ul>
<li>NIO server</li>
<li>sendfile: transferTo</li>
<li>The threading model is a single acceptor thread and N processor threads which handle a fixed number of connections each.</li>
</ul>
<h2 id="5-2-Messages"><a href="#5-2-Messages" class="headerlink" title="5.2 Messages"></a>5.2 Messages</h2><ul>
<li>Messages consist of a variable-length header, a variable length opaque key byte array and a variable length opaque value byte array.</li>
</ul>
<h2 id="5-3-Message-Format"><a href="#5-3-Message-Format" class="headerlink" title="5.3 Message Format"></a>5.3 Message Format</h2><ul>
<li>Messages (aka Records) are always written in batches.</li>
<li>Record batches and records have their own headers.</li>
</ul>
<h3 id="5-3-1-Record-Batch"><a href="#5-3-1-Record-Batch" class="headerlink" title="5.3.1 Record Batch"></a>5.3.1 Record Batch</h3><p>The following is the on-disk format of a RecordBatch.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">baseOffset: int64</span><br><span class="line">batchLength: int32</span><br><span class="line">partitionLeaderEpoch: int32</span><br><span class="line">magic: int8 (current magic value is 2)</span><br><span class="line">crc: int32</span><br><span class="line">attributes: int16</span><br><span class="line">    bit 0~2:</span><br><span class="line">        0: no compression</span><br><span class="line">        1: gzip</span><br><span class="line">        2: snappy</span><br><span class="line">        3: lz4</span><br><span class="line">    bit 3: timestampType</span><br><span class="line">    bit 4: isTransactional (0 means not transactional)</span><br><span class="line">    bit 5: isControlBatch (0 means not a control batch)</span><br><span class="line">    bit 6~15: unused</span><br><span class="line">lastOffsetDelta: int32</span><br><span class="line">firstTimestamp: int64</span><br><span class="line">maxTimestamp: int64</span><br><span class="line">producerId: int64</span><br><span class="line">producerEpoch: int16</span><br><span class="line">baseSequence: int32</span><br><span class="line">records: [Record]</span><br></pre></td></tr></table></figure></p>
<h4 id="5-3-1-1-Control-Batches"><a href="#5-3-1-1-Control-Batches" class="headerlink" title="5.3.1.1 Control Batches"></a>5.3.1.1 Control Batches</h4><ul>
<li>A control batch contains a single record called the control record.</li>
<li>Control records should not be passed on to applications.</li>
<li>Instead, they are used by consumers to filter out <strong>aborted transactional messages</strong>.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">version: int16 (current version is 0)</span><br><span class="line">type: int16 (0 indicates an abort marker, 1 indicates a commit)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="5-3-2-Record"><a href="#5-3-2-Record" class="headerlink" title="5.3.2 Record"></a>5.3.2 Record</h3><p>The on-disk format of a record with Headers is delineated below.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">length: varint</span><br><span class="line">attributes: int8</span><br><span class="line">    bit 0~7: unused</span><br><span class="line">timestampDelta: varint</span><br><span class="line">offsetDelta: varint</span><br><span class="line">keyLength: varint</span><br><span class="line">key: byte[]</span><br><span class="line">valueLen: varint</span><br><span class="line">value: byte[]</span><br><span class="line">Headers =&gt; [Header]</span><br></pre></td></tr></table></figure></p>
<h4 id="5-4-2-1-Record-Header"><a href="#5-4-2-1-Record-Header" class="headerlink" title="5.4.2.1 Record Header"></a>5.4.2.1 Record Header</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">headerKeyLength: varint</span><br><span class="line">headerKey: String</span><br><span class="line">headerValueLength: varint</span><br><span class="line">Value: byte[]</span><br></pre></td></tr></table></figure>
<h2 id="5-4-Log"><a href="#5-4-Log" class="headerlink" title="5.4 Log"></a>5.4 Log</h2><ul>
<li>A log for a topic named “my_topic” with two partitions consists of two directories (namely my_topic_0 and my_topic_1) populated with data files containing the messages for that topic.</li>
<li>Each message is uniquely identified by a 64-bit integer offset giving the byte position of the start of this message in the stream of all messages ever sent to <strong>that topic on that partition</strong> (note: the scope of offset is per partition, and <code>giving the byte position of the start of this message</code> is not quite correct, as it’s the sequential id).</li>
<li>Each log file is named with the offset of the first message it contains.</li>
</ul>
<p><em>Note: The doc is out-of-date to the latest implementation.</em></p>
<h3 id="Writes"><a href="#Writes" class="headerlink" title="Writes"></a>Writes</h3><h3 id="Reads"><a href="#Reads" class="headerlink" title="Reads"></a>Reads</h3><h3 id="Deletes"><a href="#Deletes" class="headerlink" title="Deletes"></a>Deletes</h3><p>To avoid locking reads while still allowing deletes that modify the segment list we use a copy-on-write style segment list implementation that provides consistent views to allow a binary search to proceed on an immutable static snapshot view of the log segments while deletes are progressing.</p>
<h3 id="Guarantees"><a href="#Guarantees" class="headerlink" title="Guarantees"></a>Guarantees</h3><ul>
<li>On startup a log recovery process is run that iterates over all messages in the newest log segment and verifies that each message entry is valid.<ul>
<li>A message entry is valid if the sum of its size and offset are less than the length of the file AND the CRC32 of the message payload matches the CRC stored with the message.</li>
</ul>
</li>
</ul>
<h2 id="5-5-Distribution"><a href="#5-5-Distribution" class="headerlink" title="5.5 Distribution"></a>5.5 Distribution</h2><h3 id="Consumer-Offset-Tracking"><a href="#Consumer-Offset-Tracking" class="headerlink" title="Consumer Offset Tracking"></a>Consumer Offset Tracking</h3><p>The high-level consumer tracks the maximum offset it has consumed in each partition and periodically commits its offset vector so that it can resume from those offsets in the event of a restart.</p>
<ul>
<li>Kafka provides the option to store all the offsets for a given consumer group in a designated broker (for that group) called the offset manager. i.e., any consumer instance in that consumer group should send its offset commits and fetches to that offset manager (broker).<ul>
<li>The high-level consumer handles this automatically.</li>
<li>If you use the simple consumer you will need to manage offsets manually.</li>
<li>[Scala] A consumer can look up its offset manager by issuing a GroupCoordinatorRequest to any Kafka broker and reading the GroupCoordinatorResponse which will contain the offset manager.</li>
<li>When the offset manager receives an OffsetCommitRequest, it appends the request to a special compacted Kafka topic named <strong>__consumer_offsets</strong>.</li>
<li>Record Format: [Group, Topic, Partition]::[OffsetMetadata[Offset, Metadata], CommitTime, ExpirationTime]</li>
<li>The offset manager also caches the offsets in an in-memory table in order to serve offset fetches quickly.</li>
</ul>
</li>
</ul>
<h4 id="Migrating-offsets-from-ZooKeeper-to-Kafka"><a href="#Migrating-offsets-from-ZooKeeper-to-Kafka" class="headerlink" title="Migrating offsets from ZooKeeper to Kafka"></a>Migrating offsets from ZooKeeper to Kafka</h4><h3 id="ZooKeeper-Directories"><a href="#ZooKeeper-Directories" class="headerlink" title="ZooKeeper Directories"></a>ZooKeeper Directories</h3><p>The following gives the ZooKeeper structures and algorithms used for co-ordination between consumers and brokers.</p>
<h4 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h4><h4 id="Broker-Node-Registry"><a href="#Broker-Node-Registry" class="headerlink" title="Broker Node Registry"></a>Broker Node Registry</h4><p><code>/brokers/ids/[0...N] --&gt; {&quot;jmx_port&quot;:...,&quot;timestamp&quot;:...,&quot;endpoints&quot;:[...],&quot;host&quot;:...,&quot;version&quot;:...,&quot;port&quot;:...} (ephemeral node)</code></p>
<ul>
<li>On startup, a broker node registers itself by creating a znode with the logical broker id under /brokers/ids.</li>
</ul>
<h4 id="Broker-Topic-Registry"><a href="#Broker-Topic-Registry" class="headerlink" title="Broker Topic Registry"></a>Broker Topic Registry</h4><p><code>/brokers/topics/[topic]/partitions/[0...N]/state --&gt; {&quot;controller_epoch&quot;:...,&quot;leader&quot;:...,&quot;version&quot;:...,&quot;leader_epoch&quot;:...,&quot;isr&quot;:[...]} (ephemeral node)</code></p>
<ul>
<li>Each broker registers itself under the topics it maintains and stores the number of partitions for that topic.</li>
</ul>
<h4 id="Consumers-and-Consumer-Groups"><a href="#Consumers-and-Consumer-Groups" class="headerlink" title="Consumers and Consumer Groups"></a>Consumers and Consumer Groups</h4><ul>
<li>Consumers of topics also register themselves in ZooKeeper, in order to coordinate with each other and balance the consumption of data.</li>
<li>Consumers can also store their offsets in ZooKeeper by setting offsets.storage=zookeeper.<ul>
<li>However, this offset storage mechanism will be deprecated in a future release. Therefore, it is recommended to migrate offsets storage to Kafka.</li>
</ul>
</li>
<li>Multiple consumers can form a group and jointly consume a single topic.<ul>
<li>Each consumer in the same group is given a shared group_id.</li>
<li>This group id is provided in the configuration of the consumer.</li>
<li>Each partition is consumed by exactly one consumer in a consumer group.</li>
</ul>
</li>
</ul>
<h4 id="Consumer-Id-Registry"><a href="#Consumer-Id-Registry" class="headerlink" title="Consumer Id Registry"></a>Consumer Id Registry</h4><ul>
<li>In addition to the group_id which is shared by all consumers in a group, each consumer is given a transient, unique consumer_id (of the form hostname:uuid) for identification purposes.<br><code>/consumers/[group_id]/ids/[consumer_id] --&gt; {&quot;version&quot;:...,&quot;subscription&quot;:{...:...},&quot;pattern&quot;:...,&quot;timestamp&quot;:...} (ephemeral node)</code></li>
</ul>
<h4 id="Consumer-Offsets"><a href="#Consumer-Offsets" class="headerlink" title="Consumer Offsets"></a>Consumer Offsets</h4><p><em>if offsets.storage=zookeeper</em><br><code>/consumers/[group_id]/offsets/[topic]/[partition_id] --&gt; offset_counter_value (persistent node)</code></p>
<h4 id="Partition-Owner-registry"><a href="#Partition-Owner-registry" class="headerlink" title="Partition Owner registry"></a>Partition Owner registry</h4><ul>
<li>Each broker partition is consumed by a single consumer within a given consumer group. The consumer must establish its ownership of a given partition before any consumption can begin. To establish its ownership, a consumer writes its own id in an ephemeral node under the particular broker partition it is claiming.<br><code>/consumers/[group_id]/owners/[topic]/[partition_id] --&gt; consumer_node_id (ephemeral node)</code></li>
</ul>
<h4 id="Cluster-Id"><a href="#Cluster-Id" class="headerlink" title="Cluster Id"></a>Cluster Id</h4><ul>
<li>The cluster id is a unique and immutable identifier assigned to a Kafka cluster.</li>
<li>auto-generated<br><code>/cluster/id</code></li>
</ul>
<h4 id="Broker-node-registration"><a href="#Broker-node-registration" class="headerlink" title="Broker node registration"></a>Broker node registration</h4><h4 id="Consumer-registration-algorithm"><a href="#Consumer-registration-algorithm" class="headerlink" title="Consumer registration algorithm"></a>Consumer registration algorithm</h4><p>When a consumer starts, it does the following:</p>
<ol>
<li>Register itself in the consumer id registry under its group (<code>/kafka/consumers/[group_id]/ids</code>).</li>
<li>Register a watch on changes (new consumers joining or any existing consumers leaving) under the consumer id registry. (Each change triggers rebalancing among all consumers within the group to which the changed consumer belongs.)</li>
<li>Register a watch on changes (new brokers joining or any existing brokers leaving) under the broker id registry (<code>/kafka/brokers/ids</code>). (Each change triggers rebalancing among all consumers in all consumer groups.)</li>
<li>If the consumer creates a message stream using a topic filter, it also registers a watch on changes (new topics being added) under the broker topic registry (<code>/kafka/brokers/topics</code>). (Each change will trigger re-evaluation of the available topics to determine which topics are allowed by the topic filter. A new allowed topic will trigger rebalancing among all consumers within the consumer group.)</li>
<li>Force itself to rebalance within in its consumer group.</li>
</ol>
<h4 id="Consumer-rebalancing-algorithm"><a href="#Consumer-rebalancing-algorithm" class="headerlink" title="Consumer rebalancing algorithm"></a>Consumer rebalancing algorithm</h4><p>Each consumer does the following during rebalancing:</p>
<ol>
<li>For each topic T that C<sub>i</sub> subscribes to</li>
<li>let P<sub>T</sub> be all partitions producing topic T</li>
<li>let C<sub>G</sub> be all consumers in the same group as C<sub>i</sub> that consume topic T</li>
<li>sort P<sub>T</sub> (so partitions on the same broker are clustered together)</li>
<li>sort C<sub>G</sub></li>
<li>let i be the index position of C<sub>i</sub> in C<sub>G</sub> and let N = size(P<sub>T</sub>)/size(C<sub>G</sub>)</li>
<li>assign partitions from i<em>N to (i+1)</em>N - 1 to consumer C<sub>i</sub></li>
<li>remove current entries owned by C<sub>i</sub> from the partition owner registry</li>
<li>add newly assigned partitions to the partition owner registry<br>   (we may need to re-try this until the original partition owner releases its ownership)</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><a href="https://kafka.apache.org/documentation/#design" target="_blank" rel="noopener">Kafka Design &amp; Implementation</a></li>
<li><a href="https://www.ibm.com/developerworks/library/j-zerocopy/index.html" target="_blank" rel="noopener">Efficient data transfer through zero copy</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/31/2018/01/audience_geo_analysis_using_spark_postgis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/31/2018/01/audience_geo_analysis_using_spark_postgis/" itemprop="url">Audience Geo Analysis using Spark + PostGIS</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-31T15:52:23+08:00">
                2018-01-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/postgis/" itemprop="url" rel="index">
                    <span itemprop="name">PostGIS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>Recently I’m working on a project to analyze the DeviceID/GPS carried in each Ad Request, to gain some insights in the <strong>audience geographic characteristics</strong>.</p>
<p>So, the <strong>Input Data</strong> is:</p>
<ol>
<li>Ad Request log on AWS S3, and each Ad Request contains (optionally): timestamp, device type/id, lat/lng, source app, etc.</li>
<li>POI (Place of Interest) data in PostGIS (with polygon, or just a LatLng point), e.g., Residential Neighborhood data in Shanghai.</li>
</ol>
<p>The <strong>Result Output</strong> is:</p>
<ul>
<li>Count/frequency of users from specific source POIs/Brands/Categories visiting specific destination ones.</li>
<li>maybe more…</li>
</ul>
<p>The <strong>platform and tools</strong> I’m using include:</p>
<ul>
<li><strong>AWS EC2 &amp; S3</strong></li>
<li><strong>SparkSQL + Scala</strong></li>
<li><strong>PostgreSQL + PostGIS extension</strong></li>
</ul>
<h1 id="Lessons-amp-Notes"><a href="#Lessons-amp-Notes" class="headerlink" title="Lessons &amp; Notes"></a>Lessons &amp; Notes</h1><p>After two weeks hard-working, I’m about to finish the project.<br>Just some lessons and notes I want to put down here:</p>
<h2 id="AWS-S3"><a href="#AWS-S3" class="headerlink" title="AWS S3"></a>AWS S3</h2><p>It turns out to be a <a href="http://hiack.com/2018/01/27/201801/bad-idea-using-spark-with-s3-md/">Bad Idea Using SparkSQL with S3</a>.<br>And some configurations must be paid attention to, to <a href="http://hiack.com/2018/01/10/201801/enable_spark_on_ec2_accessing_s3/">Enable Spark on AWS EC2 Accessing AWS S3</a>.</p>
<h2 id="SQL-amp-PostGIS"><a href="#SQL-amp-PostGIS" class="headerlink" title="SQL &amp; PostGIS"></a>SQL &amp; PostGIS</h2><h3 id="Plain-SQL"><a href="#Plain-SQL" class="headerlink" title="Plain SQL"></a>Plain SQL</h3><p>I choose to use PostGIS, as I need to perform some geo operations like <code>ST_DWithin, ST_Contains, ST_Distance</code>.</p>
<p>There’s a <a href="https://github.com/tminglei/slick-pg" target="_blank" rel="noopener">Slick extensions for PostgreSQL</a> available, which supports PostGIS operators in Scala.<br>Still, I decided to use <code>Plain SQL</code>, as it’s</p>
<ul>
<li>More popular (on StackOverflow)</li>
<li>Easier to learn, and deubgging (by PostgreSQL CLI)</li>
</ul>
<h3 id="DB-Connections-in-Spark-RDD"><a href="#DB-Connections-in-Spark-RDD" class="headerlink" title="DB Connections in Spark RDD"></a>DB Connections in Spark RDD</h3><p>As you may have known of,</p>
<ul>
<li>We <strong>must not</strong> create DB connections out of an RDD and use them inside.</li>
<li>And we don’t want to setup DB connections for every record, which is <strong>inefficient</strong>.</li>
</ul>
<p>So, we’d better follow the <a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html#design-patterns-for-using-foreachrdd" target="_blank" rel="noopener">Design Patterns for using foreachRDD</a>, just that I used <code>Dataset[T]::mapPartitions</code> instead.</p>
<h3 id="Spark-Lazy-Evaluation"><a href="#Spark-Lazy-Evaluation" class="headerlink" title="Spark Lazy Evaluation"></a>Spark Lazy Evaluation</h3><p>If you follow the design patterns above, you may find your Spark application fails to run due to DB connection issue (like not connected, or invalid statement).<br>That’s why you need the <code>.toList</code> operations as shown below:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> res = partitionOfRecords.flatMap &#123; rec =&gt;</span><br><span class="line">    ???</span><br><span class="line">&#125;.toList <span class="comment">// toList: force eager computation</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Alternative-to-PostGIS"><a href="#Alternative-to-PostGIS" class="headerlink" title="Alternative to PostGIS"></a>Alternative to PostGIS</h3><p>If you:</p>
<ul>
<li>Just need to calculate the geographic distance between 2 Poins (no polygon),</li>
<li>And you can tolerate losing some precision (for the specific cases below, ~0.001%)</li>
</ul>
<p>Then, you can just pass PostGIS, as show below.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">poi=# SELECT ST_distance(ST_GeomFromText('POINT(121.337293282 31.1672401193)', 4326)::geography, ST_GeomFromText('POINT(121.366448159 31.2103586192)', 4326)::geography);</span><br><span class="line">  st_distance</span><br><span class="line"><span class="comment">---------------</span></span><br><span class="line"> 5529.65840066</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">poi=# SELECT ST_distance(ST_GeomFromText('POINT(121.337293282 31.1672401193)')::geography, ST_GeomFromText('POINT(121.337393282 31.1673401193)')::geography);</span><br><span class="line"> st_distance</span><br><span class="line"><span class="comment">-------------</span></span><br><span class="line"> 14.62253234</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; :paste</span><br><span class="line"><span class="comment">// Entering paste mode (ctrl-D to finish)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">calDistanceM</span></span>(lon1: <span class="type">Double</span>, lat1: <span class="type">Double</span>, lon2: <span class="type">Double</span>, lat2: <span class="type">Double</span>): <span class="type">Double</span> =&#123;</span><br><span class="line">    <span class="comment">//pi为π，r为地球半径</span></span><br><span class="line">    <span class="keyword">val</span> pi = <span class="number">3.1415926</span></span><br><span class="line">    <span class="keyword">val</span> r: <span class="type">Double</span>  = <span class="number">6370.99681</span></span><br><span class="line">    <span class="comment">//a1、a2、b1、b2分别为上面数据的经纬度转换为弧度</span></span><br><span class="line">    <span class="keyword">val</span> a1 = lat1 * pi /<span class="number">180.0</span></span><br><span class="line">    <span class="keyword">val</span> a2 = lon1 * pi /<span class="number">180.0</span></span><br><span class="line">    <span class="keyword">val</span> b1 = lat2 * pi /<span class="number">180.0</span></span><br><span class="line">    <span class="keyword">val</span> b2 = lon2 * pi /<span class="number">180.0</span></span><br><span class="line">    <span class="keyword">var</span> t1: <span class="type">Double</span> = <span class="type">Math</span>.cos(a1) * <span class="type">Math</span>.cos(a2) * <span class="type">Math</span>.cos(b1)* <span class="type">Math</span>.cos(b2)</span><br><span class="line">    <span class="keyword">var</span> t2: <span class="type">Double</span> = <span class="type">Math</span>.cos(a1) * <span class="type">Math</span>.sin(a2) * <span class="type">Math</span>.cos(b1)* <span class="type">Math</span>.sin(b2)</span><br><span class="line">    <span class="keyword">var</span> t3: <span class="type">Double</span> = <span class="type">Math</span>.sin(a1) * <span class="type">Math</span>.sin(b1)</span><br><span class="line">    <span class="keyword">val</span> distance = <span class="type">Math</span>.acos(t1 + t2 + t3) * r</span><br><span class="line">    distance * <span class="number">1000</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Exiting paste mode, now interpreting.</span></span><br><span class="line"></span><br><span class="line">calDistanceM: (lon1: <span class="type">Double</span>, lat1: <span class="type">Double</span>, lon2: <span class="type">Double</span>, lat2: <span class="type">Double</span>)<span class="type">Double</span></span><br><span class="line"></span><br><span class="line">scala&gt; calDistanceM(<span class="number">121.337293282</span>, <span class="number">31.1672401193</span>, <span class="number">121.366448159</span>, <span class="number">31.2103586192</span>)</span><br><span class="line">res0: <span class="type">Double</span> = <span class="number">5538.864157826987</span></span><br><span class="line"></span><br><span class="line">scala&gt; calDistanceM(<span class="number">121.337293282</span>, <span class="number">31.1672401193</span>, <span class="number">121.337393282</span>, <span class="number">31.1673401193</span>)</span><br><span class="line">res1: <span class="type">Double</span> = <span class="number">14.634816191814881</span></span><br></pre></td></tr></table></figure>
<h3 id="Bottleneck"><a href="#Bottleneck" class="headerlink" title="Bottleneck"></a>Bottleneck</h3><p>I use <code>m3.medium</code> for Spark Master/Workers, and <code>m4.4xlarge</code> for PostGIS server, and the instance count ratio is <em>20:1</em>.<br>For my typical jobs, the CPU usage is ~50%, and seems the bottleneck is the networking, before I start the optimization of the pipeline.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><em>from Spark official docs, Stackoverflow and other web resources…</em></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/27/2018/01/bad-idea-using-spark-with-s3-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/27/2018/01/bad-idea-using-spark-with-s3-md/" itemprop="url">Bad Idea Using SparkSQL with S3</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-27T23:23:24+08:00">
                2018-01-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/aws-s3/" itemprop="url" rel="index">
                    <span itemprop="name">AWS S3</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>In my recent project <a href="http://hiack.com/2018/01/21/audience_geo_analysis_using_spark_postgis/">Audience Geo Analysis using Spark + PostGis</a>, I use <strong>AWS S3</strong> as the source &amp; destination data store.<br>Although, </p>
<ul>
<li>I’m aware that AWS S3 is <strong>an object store but not a true file system</strong>, and,</li>
<li>I’ve heard of that the AWS S3 <strong>consistency model</strong> may cause some problem to Spark (or other similar big data applications), and</li>
<li>I configured my app specifically for this, as:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2</span><br><span class="line">spark.speculation false</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Yet I got a punch in my face.</p>
<p>The <strong>background</strong> is, I need to create 2 tables from large log data and perform a join operation on them.<br>In case any of them fails and I don’t want to waste time in re-running the full pipeline, I submitted 3 jobs separately in sequence: I put the 3 <code>spark-submit</code> in a shell script and ran it in background, and then I went to sleep.  </p>
<p>The final <code>join</code> job looks like:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df1.orderBy(<span class="string">"uid"</span>).show</span><br><span class="line"></span><br><span class="line">+----+----+---+</span><br><span class="line">| uid| hid| sv|</span><br><span class="line">+----+----+---+</span><br><span class="line">|uid1|hid2| <span class="number">10</span>|</span><br><span class="line">|uid1|hid1| <span class="number">10</span>|</span><br><span class="line">|uid1|hid3| <span class="number">10</span>|</span><br><span class="line">|uid2|hid1|  <span class="number">2</span>|</span><br><span class="line">|uid3|hid2| <span class="number">10</span>|</span><br><span class="line">|uid4|hid2|  <span class="number">3</span>|</span><br><span class="line">|uid5|hid3|  <span class="number">5</span>|</span><br><span class="line">+----+----+---+</span><br><span class="line"></span><br><span class="line">scala&gt; df2.orderBy(<span class="string">"uid"</span>).show</span><br><span class="line"></span><br><span class="line">+----+----+---+</span><br><span class="line">| uid| pid| sv|</span><br><span class="line">+----+----+---+</span><br><span class="line">|uid1|pid2|  <span class="number">2</span>|</span><br><span class="line">|uid1|pid1|  <span class="number">1</span>|</span><br><span class="line">|uid2|pid1|  <span class="number">2</span>|</span><br><span class="line">|uid3|pid1|  <span class="number">3</span>|</span><br><span class="line">|uid3|pidx|<span class="number">999</span>|</span><br><span class="line">|uid3|pid2|  <span class="number">4</span>|</span><br><span class="line">|uidx|pid1|  <span class="number">2</span>|</span><br><span class="line">+----+----+---+</span><br><span class="line"></span><br><span class="line">scala&gt; df1.drop(<span class="string">"sv"</span>)</span><br><span class="line">  .join(df2, <span class="string">"uid"</span>)</span><br><span class="line">  .groupBy(<span class="string">"hid"</span>, <span class="string">"pid"</span>)</span><br><span class="line">  .agg(count(<span class="string">"*"</span>) as <span class="string">"xcnt"</span>, sum(<span class="string">"sv"</span>) as <span class="string">"xsum"</span>, avg(<span class="string">"sv"</span>) as <span class="string">"xavg"</span>)</span><br><span class="line">  .orderBy(<span class="string">"hid"</span>).show</span><br><span class="line"></span><br><span class="line">+----+----+----+----+-----+</span><br><span class="line">| hid| pid|xcnt|xsum| xavg|</span><br><span class="line">+----+----+----+----+-----+</span><br><span class="line">|hid1|pid1|   <span class="number">2</span>|   <span class="number">3</span>|  <span class="number">1.5</span>|</span><br><span class="line">|hid1|pid2|   <span class="number">1</span>|   <span class="number">2</span>|  <span class="number">2.0</span>|</span><br><span class="line">|hid2|pid2|   <span class="number">2</span>|   <span class="number">6</span>|  <span class="number">3.0</span>|</span><br><span class="line">|hid2|pidx|   <span class="number">1</span>| <span class="number">999</span>|<span class="number">999.0</span>|</span><br><span class="line">|hid2|pid1|   <span class="number">2</span>|   <span class="number">4</span>|  <span class="number">2.0</span>|</span><br><span class="line">|hid3|pid1|   <span class="number">1</span>|   <span class="number">1</span>|  <span class="number">1.0</span>|</span><br><span class="line">|hid3|pid2|   <span class="number">1</span>|   <span class="number">2</span>|  <span class="number">2.0</span>|</span><br><span class="line">+----+----+----+----+-----+</span><br></pre></td></tr></table></figure></p>
<p>When I checked the final result today, I was so surprised there were <strong>duplicate <code>(hid, pid)</code> rows</strong> in it.  </p>
<p>At first, I thought I was mis-using the SparkSQL operators, and spent much time debugging it. But when I tried to reproduce it in Spark-Shell. everything was just fine.   </p>
<p>Finnaly, I realized, <strong><em>probably</em></strong>, the root cause is AWS S3 consistency model.<br>I’m not totally sure of it, but got no other choice.  </p>
<p>So, the workaround is,</p>
<ul>
<li>Put the 3 jobs in a single Spark app, or</li>
<li>Run the dependent down-stream job (like the final join job) later for a while.</li>
</ul>
<p>I haven’t verified them both, but at least the 2nd works for me.</p>
<p>The lesson is, <strong>if you have another choice like HDFS, you’d better just pass AWS S3 as the intermediate big data storage</strong>.</p>
<p><strong><em>[Update]</em></strong></p>
<ul>
<li>I’m almost sure it’s the AWS S3’s problem now.</li>
<li>As last time when I copied the result data from S3 to local host, soon after the job was done, the downloaded data contained some records not supposed to be there.</li>
<li>But when I re-downloaded the same bucket from S3, the data turned to be correct.</li>
<li>So what else could it be?</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel" target="_blank" rel="noopener">Amazon S3 Data Consistency Model</a></li>
<li><a href="https://medium.com/@subhojit20_27731/apache-spark-and-amazon-s3-gotchas-and-best-practices-a767242f3d98" target="_blank" rel="noopener">Apache Spark and Amazon S3 — Gotchas and best practices</a><br>-<a href="https://hortonworks.com/blog/s3guard-amazon-s3-consistency/" target="_blank" rel="noopener">USING S3GUARD FOR AMAZON S3 CONSISTENCY</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/24/2018/01/window-frame-in-postgresl-spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/24/2018/01/window-frame-in-postgresl-spark/" itemprop="url">Window Frame in PostgreSQL and SparkSQL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-24T13:40:35+08:00">
                2018-01-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/postgresql/" itemprop="url" rel="index">
                    <span itemprop="name">PostgreSQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>I need to select the top row out of each <em>row group (row window)</em> partitioned by some rule, from a PostgreSQL and SparkSQl table, that’s what <strong>Window Frame</strong> is about.<br>Just copy some examples from other articles/docs (as listed in the <em>Reference</em> Section) to show the concept and related operations of <strong>Window Frame</strong> and <strong>Window Functions</strong>, in PostgreSQL.<br>Stackoverflow has plenty of examples showing the use in SparkSQL.   </p>
<h1 id="Concept-amp-Operations-in-PostgreSQL"><a href="#Concept-amp-Operations-in-PostgreSQL" class="headerlink" title="Concept &amp; Operations in PostgreSQL"></a>Concept &amp; Operations in PostgreSQL</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">postgres=# select * from empsal ;</span><br><span class="line">  depname  | empno | salary</span><br><span class="line"><span class="comment">-----------+-------+--------</span></span><br><span class="line"> develop   |    11 |   5200</span><br><span class="line"> develop   |     7 |   4200</span><br><span class="line"> develop   |     9 |   4500</span><br><span class="line"> develop   |     8 |   6000</span><br><span class="line"> develop   |    10 |   5200</span><br><span class="line"> personnel |     5 |   3500</span><br><span class="line"> personnel |     2 |   3900</span><br><span class="line"> sales     |     3 |   4800</span><br><span class="line"> sales     |     1 |   5000</span><br><span class="line"> sales     |     4 |   4800</span><br><span class="line">(10 rows)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">postgres=# SELECT depname, empno, salary, avg(salary) OVER (PARTITION BY depname) FROM empsal;</span><br><span class="line">  depname  | empno | salary |          avg          </span><br><span class="line"><span class="comment">-----------+-------+--------+-----------------------</span></span><br><span class="line"> develop   |    11 |   5200 | 5020.0000000000000000</span><br><span class="line"> develop   |     7 |   4200 | 5020.0000000000000000</span><br><span class="line"> develop   |     9 |   4500 | 5020.0000000000000000</span><br><span class="line"> develop   |     8 |   6000 | 5020.0000000000000000</span><br><span class="line"> develop   |    10 |   5200 | 5020.0000000000000000</span><br><span class="line"> personnel |     5 |   3500 | 3700.0000000000000000</span><br><span class="line"> personnel |     2 |   3900 | 3700.0000000000000000</span><br><span class="line"> sales     |     3 |   4800 | 4866.6666666666666667</span><br><span class="line"> sales     |     1 |   5000 | 4866.6666666666666667</span><br><span class="line"> sales     |     4 |   4800 | 4866.6666666666666667</span><br><span class="line">(10 rows)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">postgres=# SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary DESC) FROM empsal;</span><br><span class="line">  depname  | empno | salary | rank </span><br><span class="line"><span class="comment">-----------+-------+--------+------</span></span><br><span class="line"> develop   |     8 |   6000 |    1</span><br><span class="line"> develop   |    10 |   5200 |    2</span><br><span class="line"> develop   |    11 |   5200 |    2</span><br><span class="line"> develop   |     9 |   4500 |    4</span><br><span class="line"> develop   |     7 |   4200 |    5</span><br><span class="line"> personnel |     2 |   3900 |    1</span><br><span class="line"> personnel |     5 |   3500 |    2</span><br><span class="line"> sales     |     1 |   5000 |    1</span><br><span class="line"> sales     |     3 |   4800 |    2</span><br><span class="line"> sales     |     4 |   4800 |    2</span><br><span class="line">(10 rows)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> depname, empno, salary</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">  (<span class="keyword">SELECT</span> depname, empno, salary,</span><br><span class="line">          <span class="keyword">rank</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> depname <span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span>, empno) <span class="keyword">AS</span> pos</span><br><span class="line">     <span class="keyword">FROM</span> empsal</span><br><span class="line">  ) <span class="keyword">AS</span> ss</span><br><span class="line"><span class="keyword">WHERE</span> pos &lt; <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">postgres=# SELECT depname, empno, salary</span><br><span class="line">postgres-# FROM</span><br><span class="line">postgres-#   (SELECT depname, empno, salary,</span><br><span class="line">postgres(#           rank() OVER (PARTITION BY depname ORDER BY salary DESC, empno) AS pos</span><br><span class="line">postgres(#      FROM empsal</span><br><span class="line">postgres(#   ) AS ss</span><br><span class="line">postgres-# WHERE pos &lt; 3;</span><br><span class="line">  depname  | empno | salary </span><br><span class="line"><span class="comment">-----------+-------+--------</span></span><br><span class="line"> develop   |     8 |   6000</span><br><span class="line"> develop   |    10 |   5200</span><br><span class="line"> personnel |     2 |   3900</span><br><span class="line"> personnel |     5 |   3500</span><br><span class="line"> sales     |     1 |   5000</span><br><span class="line"> sales     |     3 |   4800</span><br><span class="line">(6 rows)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">sum</span>(salary) <span class="keyword">OVER</span> w, <span class="keyword">avg</span>(salary) <span class="keyword">OVER</span> w</span><br><span class="line">  <span class="keyword">FROM</span> empsal</span><br><span class="line">  WINDOW w <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> depname <span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span>);</span><br><span class="line"></span><br><span class="line">postgres=# SELECT sum(salary) OVER w, avg(salary) OVER w</span><br><span class="line">postgres-#   FROM empsal</span><br><span class="line">postgres-#   WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);</span><br><span class="line">  sum  |          avg          </span><br><span class="line"><span class="comment">-------+-----------------------</span></span><br><span class="line">  6000 | 6000.0000000000000000</span><br><span class="line"> 16400 | 5466.6666666666666667</span><br><span class="line"> 16400 | 5466.6666666666666667</span><br><span class="line"> 20900 | 5225.0000000000000000</span><br><span class="line"> 25100 | 5020.0000000000000000</span><br><span class="line">  3900 | 3900.0000000000000000</span><br><span class="line">  7400 | 3700.0000000000000000</span><br><span class="line">  5000 | 5000.0000000000000000</span><br><span class="line"> 14600 | 4866.6666666666666667</span><br><span class="line"> 14600 | 4866.6666666666666667</span><br><span class="line">(10 rows)</span><br></pre></td></tr></table></figure>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.postgresql.org/docs/10/static/tutorial-window.html" target="_blank" rel="noopener">Window Functions</a><br><a href="http://time-track.cn/postgresql-window-function.html" target="_blank" rel="noopener">PostgreSQL窗口函数</a><br><a href="https://stackoverflow.com/questions/33878370/how-to-select-the-first-row-of-each-group" target="_blank" rel="noopener">How to select the first row of each group?</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/23/2018/01/use-overridable-in-constructor-in-cpp-java-scala-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/23/2018/01/use-overridable-in-constructor-in-cpp-java-scala-md/" itemprop="url">Use Overridable in Constructor in C++, Java and Scala</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-23T14:18:28+08:00">
                2018-01-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/c/" itemprop="url" rel="index">
                    <span itemprop="name">C++</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/c/scala/" itemprop="url" rel="index">
                    <span itemprop="name">Scala</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/c/scala/java/" itemprop="url" rel="index">
                    <span itemprop="name">Java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>So we all know that in object-oriented programming, the use of overridable constructs like virtual functions or overridable variables (in Scala) in <strong>Constructor</strong> must be avoided, or at least be carefully examined.<br>But if you insist to referencing the overridable in constructors,  there’re some subtile distinctions between C++ and Java (as well as Scala) you’d better know of.</p>
<p>As mentioned by <code>Scala for the Impatient (2nd. Edition)</code> in <code>Chapter 8</code>:  </p>
<blockquote>
<p>NOTE: At the root of the construction order problem lies a design decision of the Java language - namely, to allow the invocation of subclass methods in a superclass constructor.<br>In C++, an object’s virtual function table pointer is set to the table of the superclass when the superclass constructor executes. Afterwards, the pointer is set to the subclass table. Therefore, in C++, it is not possible to modify constructor behavior through overriding.<br>The Java designers felt that this subtlety was unnecessary, and the Java virtual machine does not adjust the virtual function table during construction.</p>
</blockquote>
<p>To put it straight, if you call an overridable method in the base class constructor, which is overridden in the subclass, the resulting call goes to:  </p>
<ul>
<li><strong>in C++: the base class method</strong><br> actually this means the virtual function doesn’t work at all in the constructor</li>
<li><p><strong>in Java/Scala: the sub class method</strong><br> and if the sub class method references some member variables defined in sub class, it could be a problem as the subclass members are not initialized yet.</p>
</li>
<li><p><strong>C++</strong>  </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Base() &#123; <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Base::Constructing "</span> + name() + <span class="string">"..."</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; ; &#125;</span><br><span class="line">    <span class="keyword">virtual</span> ~Base() &#123;&#125;</span><br><span class="line">    <span class="keyword">virtual</span> <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">"Base"</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span> <span class="keyword">public</span> Base &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Derived(): Base(), nickname(<span class="string">"Subclass"</span>) &#123; <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Derived::Constructing "</span> + name() + <span class="string">"..."</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; &#125;</span><br><span class="line">    <span class="keyword">virtual</span> <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">"Derived/"</span> + nickname; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> nickname;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Base* b = <span class="keyword">new</span> Derived();</span><br><span class="line">    (<span class="keyword">void</span>)b;</span><br><span class="line">    <span class="comment">/* Output:</span></span><br><span class="line"><span class="comment">       Base::Constructing Base...</span></span><br><span class="line"><span class="comment">       Derived::Constructing Derived/Subclass...</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Java</strong>  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cj;</span><br><span class="line"></span><br><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">Base</span> </span>&#123;</span><br><span class="line">    Base() &#123;</span><br><span class="line">        System.out.println(<span class="string">"Base::Constructing "</span> + name() + <span class="string">"..."</span> );</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">"Base"</span>; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span> <span class="keyword">extends</span> <span class="title">Base</span> </span>&#123;</span><br><span class="line">    Derived() &#123;</span><br><span class="line">        nickname = <span class="string">"Subclsass"</span>;</span><br><span class="line">        System.out.println(<span class="string">"Derived::Constructing "</span> + name() + <span class="string">"..."</span> );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">"Derived"</span> + <span class="string">"/"</span> + nickname; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String nickname;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Derived();</span><br><span class="line">        <span class="comment">/* Output</span></span><br><span class="line"><span class="comment">            Base::Constructing Derived/null...</span></span><br><span class="line"><span class="comment">            Derived::Constructing Derived/Subclsass...</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Scala</strong>  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cj</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Creature</span>  </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> range: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line">  <span class="keyword">val</span> env: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Int</span>](range)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ant</span> <span class="keyword">extends</span> <span class="title">Creature</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">val</span> range = <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Ant</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>() = <span class="keyword">new</span> <span class="type">Ant</span>()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Main</span> <span class="keyword">extends</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> ant = <span class="type">Ant</span>()</span><br><span class="line">  <span class="type">System</span>.out.println(<span class="string">s"Ant.env.length = <span class="subst">$&#123;ant.env.length&#125;</span>"</span>)</span><br><span class="line">  <span class="type">System</span>.out.println(<span class="string">s"Ant.range = <span class="subst">$&#123;ant.range&#125;</span>"</span>)</span><br><span class="line">  <span class="comment">/* Output:</span></span><br><span class="line"><span class="comment">      Ant.env.length = 0</span></span><br><span class="line"><span class="comment">      Ant.range = 2</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/19/2018/01/cut_csv_in_dos/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/19/2018/01/cut_csv_in_dos/" itemprop="url">Weird Result when Cut CSV Files in DOS Format</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-19T18:08:56+08:00">
                2018-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/shell/" itemprop="url" rel="index">
                    <span itemprop="name">Shell</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>It happened again.<br>So maybe I should put it down here.  </p>
<p>I converted a Mac Numbers file to CSV file (whose columns were copied from an Excel file), and the file looks like this in Vim:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[cj ~/Downloads]$ head  xxx.csv</span><br><span class="line">31.19294,121.44045</span><br><span class="line">31.23328,121.47479</span><br><span class="line">31.27414,121.45309</span><br><span class="line">31.19335,121.43978</span><br><span class="line">31.23511,121.49741</span><br></pre></td></tr></table></figure></p>
<p>But, when you cut it, the output looks like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[cj ~/Downloads]$ awk -F<span class="string">','</span> <span class="string">'&#123;OFS=","; print "["$2,$1"],"&#125;'</span> xxx.csv | head</span><br><span class="line">,31.19294],</span><br><span class="line">,31.23328],</span><br><span class="line">,31.27414],</span><br><span class="line">,31.19335],</span><br><span class="line">,31.23511],</span><br></pre></td></tr></table></figure></p>
<p>If you open the file with Vim, you may notice the hint at the bottom: <code>&quot;xxx.csv&quot; [dos] 587L, 11616C</code>.<br>And you just check the file in hex format in Vim, by: <code>:%!xxd</code>, you will find the root cause:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">00000000: 3331 2e31 3932 3934 2c31 3231 2e34 3430  31.19294,121.440</span><br><span class="line">00000010: 3435 0d0a 3331 2e32 3333 3238 2c31 3231  45..31.23328,121</span><br></pre></td></tr></table></figure></p>
<p>Note the <code>0d0a</code>.  </p>
<p>In Unix format, it looks like:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">00000000: 3331 2e31 3932 3934 2c31 3231 2e34 3430  31.19294,121.440</span><br><span class="line">00000010: 3435 0a33 312e 3233 3332 382c 3132 312e  45.31.23328,121.</span><br><span class="line">00000020: 3437 3437 390a                           47479.</span><br></pre></td></tr></table></figure></p>
<p>Just <code>0a</code>.  </p>
<p>So, you just need to <code>dos2unix xxx.csv</code> (<code>brew install dos2unix1</code> if it’s absent).  </p>
<p>And, a note irrelevant to this topic:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -n <span class="string">'/18\/01\/17 10:49/,/18\/01\/17 10:55/p'</span> some-service.log</span><br></pre></td></tr></table></figure></p>
<p>, to filter for logs within the date/time range.  </p>
<p>When I was working in the giant internet company, I used to use this command to check for error logs happened within some time window to debug online issue.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/11/2018/01/enable_public_host_name_in_spark_webui/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/11/2018/01/enable_public_host_name_in_spark_webui/" itemprop="url">Enable Public Host Name in Spark Web UI</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-11T18:08:56+08:00">
                2018-01-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>My Spark cluster (standalone) setup in AWS EC2 is assuming internal IP addresses in the WebUI (by default) for links to Master and Workers, and thus I cannot go freely among them.</p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="bash"><span class="keyword">for</span> h <span class="keyword">in</span> $(cat slaves)
<span class="keyword">do</span>
  ssh &lt;user&gt;@<span class="variable">$h</span> <span class="string">"sudo sh -c \"echo export SPARK_PUBLIC_DNS=<span class="variable">$h</span> &gt;&gt; /path/to/spark/conf/spark-env.sh\""</span>
<span class="keyword">done</span>
</code></pre>
<p>Don’t forget the master server.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/11/2018/01/redirect_with_sudo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/11/2018/01/redirect_with_sudo/" itemprop="url">Permission Denied when sudo with io redirect</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-11T15:08:56+08:00">
                2018-01-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/shell/" itemprop="url" rel="index">
                    <span itemprop="name">Shell</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p><code>ssh user1@somehost &quot;sudo echo &gt;&gt; /home/user2/xxx&quot;</code> will result in <code>Permission denied</code>.</p>
<p>The root cause is the redirection is performed by the login shell, which does not have the permission.<br>The redirection of the output is <strong>not</strong> performed by sudo.  </p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><ul>
<li>Run a shell with sudo and give the command to it by using the <code>-c</code> option:<br><code>sudo sh -c &#39;ls -hal /root/ &gt; /root/test.out&#39;</code></li>
<li><p>Create a script with your commands and run that script with sudo:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">ls -hal /root/ &gt; /root/test.out</span><br></pre></td></tr></table></figure>
<p>or  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo bash &lt;&lt;EOF</span><br><span class="line">ls -hal /root/ &gt; /root/test.out</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>or  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'ls -hal /root/ &gt; /root/test.out'</span> | sudo bash</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>For more, refer to <a href="https://stackoverflow.com/questions/82256/how-do-i-use-sudo-to-redirect-output-to-a-location-i-dont-have-permission-to-wr/16514624#16514624" target="_blank" rel="noopener">StackOverflow</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hiack.com/2018/01/10/2018/01/enable_spark_on_ec2_accessing_s3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ's SpaceX">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/10/2018/01/enable_spark_on_ec2_accessing_s3/" itemprop="url">Enable Spark on AWS EC2 Accessing AWS S3</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-10T18:08:56+08:00">
                2018-01-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/devops/" itemprop="url" rel="index">
                    <span itemprop="name">DevOps</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>I setup a Spark Standalone cluster on AWS EC2 (region: cn-north-1).<br>And I build a Simple Spark application in Scala, which reads from and writes to AWS S3.<br>Regarding the <code>SecurityException</code> issue, refer to <a href="http://hiack.com/2018/01/15/spark_class_not_found/">ClassNotFoundException/SecurityException in Spark+sbt</a>.  </p>
<p>To enable Spark accessing AWS S3, some config must be taken care of, including:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--deploy-mode client \</span><br><span class="line">--driver-memory 2400m \</span><br><span class="line">--executor-memory 2400m \</span><br><span class="line">--conf spark.executor.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4=<span class="literal">true</span> \</span><br><span class="line">--conf spark.driver.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4=<span class="literal">true</span> \</span><br><span class="line">--conf spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2 \</span><br><span class="line">--conf spark.speculation=<span class="literal">false</span> \</span><br><span class="line">--conf spark.hadoop.fs.s3a.region=cn-north-1 \</span><br><span class="line">--conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \</span><br><span class="line">--conf spark.hadoop.fs.s3a.endpoint=s3.cn-north-1.amazonaws.com.cn \</span><br><span class="line">--conf spark.hadoop.fs.s3a.access.key=******************** \</span><br><span class="line">--conf spark.hadoop.fs.s3a.secret.key=**************************************** \</span><br></pre></td></tr></table></figure></p>
<p>If you want to hard code them in the source code:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sc.hadoopConfiguration.set(<span class="string">"fs.s3a.endpoint"</span>, <span class="string">"s3.cn-north-1.amazonaws.com.cn"</span>)</span><br><span class="line">sc.hadoopConfiguration.set(<span class="string">"fs.s3a.impl"</span>, <span class="string">"org.apache.hadoop.fs.s3a.S3AFileSystem"</span>)</span><br><span class="line">sc.hadoopConfiguration.set(<span class="string">"fs.s3a.region"</span>, <span class="string">"cn-north-1"</span>)</span><br><span class="line"><span class="comment">//sc.hadoopConfiguration.set("fs.s3a.awsAccessKeyId", "********************")</span></span><br><span class="line"><span class="comment">//sc.hadoopConfiguration.set("fs.s3a.awsSecretAccessKey", "****************************************")</span></span><br><span class="line">sc.hadoopConfiguration.set(<span class="string">"fs.s3a.access.key"</span>, <span class="string">"********************"</span>)</span><br><span class="line">sc.hadoopConfiguration.set(<span class="string">"fs.s3a.secret.key"</span>, <span class="string">"****************************************"</span>)</span><br></pre></td></tr></table></figure></p>
<p>Or, set them in the <code>spark-env.sh</code>.  </p>
<p>I haven’t made it work in the cluster mode, without mannually coping the jars to the cluster nodes.</p>
<p><strong>Note:</strong>  </p>
<ul>
<li>There’re several ways AWS keys being captured by Spark, like spark-submit config, Spark/bash env, ~/.aws/credentials, etc. Just try it.</li>
<li>If the input/output args to your Spark application are S3 paths, you might need to specify the paths with schema <strong><code>s3a://...</code></strong></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CJ</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CJ</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
